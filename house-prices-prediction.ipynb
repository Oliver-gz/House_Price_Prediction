{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-25T03:41:10.613714Z","iopub.execute_input":"2022-05-25T03:41:10.614838Z","iopub.status.idle":"2022-05-25T03:41:10.632554Z","shell.execute_reply.started":"2022-05-25T03:41:10.614795Z","shell.execute_reply":"2022-05-25T03:41:10.631773Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# 0 Read the Data\nData description:\n\n- target: SalePrice\n- We have 79 features, some of which have missing values\n- We need to check the data types and distributions of each feature and the target","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom scipy.stats import norm\nimport scipy.stats as spst\n\nimport pylab\nimport missingno as msno\n\nfrom sklearn.preprocessing import PowerTransformer, OneHotEncoder, StandardScaler\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, KFold\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.svm import SVR, LinearSVR\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, ExtraTreesRegressor\nfrom xgboost import XGBRegressor\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_columns', 300)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:11.638073Z","iopub.execute_input":"2022-05-25T03:41:11.638493Z","iopub.status.idle":"2022-05-25T03:41:13.434838Z","shell.execute_reply.started":"2022-05-25T03:41:11.638462Z","shell.execute_reply":"2022-05-25T03:41:13.434099Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv', index_col='Id')\ndf_test = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv', index_col='Id')\n# y = df_train['SalePrice']\n# df_train = df_train.drop('SalePrice', axis=1)\n# df = pd.concat([df_train, df_test])","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:13.436660Z","iopub.execute_input":"2022-05-25T03:41:13.437206Z","iopub.status.idle":"2022-05-25T03:41:13.529353Z","shell.execute_reply.started":"2022-05-25T03:41:13.437158Z","shell.execute_reply":"2022-05-25T03:41:13.528502Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:13.530630Z","iopub.execute_input":"2022-05-25T03:41:13.531544Z","iopub.status.idle":"2022-05-25T03:41:13.596208Z","shell.execute_reply.started":"2022-05-25T03:41:13.531492Z","shell.execute_reply":"2022-05-25T03:41:13.595072Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(df_train.shape, df_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:13.990159Z","iopub.execute_input":"2022-05-25T03:41:13.990780Z","iopub.status.idle":"2022-05-25T03:41:13.997526Z","shell.execute_reply.started":"2022-05-25T03:41:13.990713Z","shell.execute_reply":"2022-05-25T03:41:13.996365Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# 1 EDA","metadata":{}},{"cell_type":"markdown","source":"## 1.1 Variable Types\nTotally there are 79 feature variables, including 33 numerical variables and 46 categorical variables. In detail, 14 are discrete, 20 are continuous, 23 are nominal, and 23 are ordinal.","metadata":{}},{"cell_type":"code","source":"#14\nDISCRETE = ['BsmtFullBath','BsmtHalfBath','BedroomAbvGr','FullBath','Fireplaces','GarageYrBlt','GarageCars','HalfBath',\n            'KitchenAbvGr','MoSold','TotRmsAbvGrd','YearBuilt','YearRemodAdd','YrSold']\n#20\nCONTINUOUS = ['1stFlrSF','2ndFlrSF','3SsnPorch','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','EnclosedPorch','GrLivArea',\n              'GarageArea','LotArea','LotFrontage','LowQualFinSF','MasVnrArea','MiscVal','OpenPorchSF','PoolArea',\n              'WoodDeckSF','ScreenPorch','TotalBsmtSF']\n#23\nNOMINAL = ['Alley','BldgType','Condition1','Condition2','CentralAir','Exterior1st','Exterior2nd','Foundation',\n           'GarageType','HouseStyle','Heating','LandContour','LotConfig','MSSubClass','MSZoning','MasVnrType',\n           'MiscFeature','Neighborhood','RoofStyle','RoofMatl','Street','SaleType','SaleCondition']\n#23\nORDINAL = ['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','ExterCond','ExterQual','Electrical',\n           'Functional','FireplaceQu','Fence','GarageFinish','GarageQual','GarageCond','HeatingQC','KitchenQual',\n           'LotShape','LandSlope','OverallQual','OverallCond','PavedDrive','PoolQC','Utilities']\n\nNUMERICAL = DISCRETE + CONTINUOUS\nCATEGORICAL = NOMINAL + ORDINAL\nprint(len(DISCRETE),len(CONTINUOUS),len(NOMINAL),len(ORDINAL))\nprint(len(NUMERICAL), len(CATEGORICAL))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:14.806087Z","iopub.execute_input":"2022-05-25T03:41:14.806527Z","iopub.status.idle":"2022-05-25T03:41:14.821475Z","shell.execute_reply.started":"2022-05-25T03:41:14.806496Z","shell.execute_reply":"2022-05-25T03:41:14.820438Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#some variables need to be transformed from int to str\ndf_train[CATEGORICAL].dtypes[df_train[CATEGORICAL].dtypes != object]","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:15.443576Z","iopub.execute_input":"2022-05-25T03:41:15.443899Z","iopub.status.idle":"2022-05-25T03:41:15.460340Z","shell.execute_reply.started":"2022-05-25T03:41:15.443863Z","shell.execute_reply":"2022-05-25T03:41:15.459207Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df_train[NUMERICAL].dtypes[df_train[NUMERICAL].dtypes == object]","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:16.097713Z","iopub.execute_input":"2022-05-25T03:41:16.098057Z","iopub.status.idle":"2022-05-25T03:41:16.108714Z","shell.execute_reply.started":"2022-05-25T03:41:16.098022Z","shell.execute_reply":"2022-05-25T03:41:16.107844Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## 1.2 Missing Values","metadata":{}},{"cell_type":"markdown","source":"### 1.2.1 Variable Names and Missing Percentage","metadata":{}},{"cell_type":"code","source":"def plot_missing_percentage(df, note=True):\n    num = sum(df.isnull().sum() != 0) #missing number\n    missing_total = df.isnull().sum().sort_values(ascending=False)\n    missing_percent = (df.isnull().sum() / len(df)).sort_values(ascending=False)\n\n    missing_total.head(num).plot(kind='barh', figsize=(16,10), fontsize=12)\n    plt.xlabel('Number of missing values', fontsize=12)\n    plt.title('Variables with missing values', fontsize=12)\n    if note:\n        for a,b,c in zip(range(num), missing_total.head(num), missing_percent.head(num)):\n            plt.text(b+40, a, '%.3f' % c, ha='center', va='center', fontsize=12)\n        \n    return list(missing_total.head(num).index)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:16.733978Z","iopub.execute_input":"2022-05-25T03:41:16.735119Z","iopub.status.idle":"2022-05-25T03:41:16.744965Z","shell.execute_reply.started":"2022-05-25T03:41:16.735065Z","shell.execute_reply":"2022-05-25T03:41:16.743864Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_missing_list = plot_missing_percentage(df_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:17.381791Z","iopub.execute_input":"2022-05-25T03:41:17.382441Z","iopub.status.idle":"2022-05-25T03:41:17.780033Z","shell.execute_reply.started":"2022-05-25T03:41:17.382402Z","shell.execute_reply":"2022-05-25T03:41:17.779018Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"test_missing_list = plot_missing_percentage(df_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:18.027816Z","iopub.execute_input":"2022-05-25T03:41:18.028383Z","iopub.status.idle":"2022-05-25T03:41:18.575240Z","shell.execute_reply.started":"2022-05-25T03:41:18.028335Z","shell.execute_reply":"2022-05-25T03:41:18.574377Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### 1.2.2 Missing Value Distribution","metadata":{}},{"cell_type":"code","source":"#check if there are missing values in train/test/both\ntrain_test_missing_both = []\ntrain_missing_only = []\ntest_missing_only = []\n\nfor var in set(train_missing_list + test_missing_list):\n    if var in train_missing_list:\n        if var in test_missing_list: train_test_missing_both.append(var)\n        else: train_missing_only.append(var)\n    else: test_missing_only.append(var)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:18.685833Z","iopub.execute_input":"2022-05-25T03:41:18.686284Z","iopub.status.idle":"2022-05-25T03:41:18.691830Z","shell.execute_reply.started":"2022-05-25T03:41:18.686250Z","shell.execute_reply":"2022-05-25T03:41:18.690861Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"set(train_test_missing_both)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:19.337645Z","iopub.execute_input":"2022-05-25T03:41:19.337999Z","iopub.status.idle":"2022-05-25T03:41:19.344730Z","shell.execute_reply.started":"2022-05-25T03:41:19.337965Z","shell.execute_reply":"2022-05-25T03:41:19.344087Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"set(train_missing_only)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:19.981563Z","iopub.execute_input":"2022-05-25T03:41:19.982233Z","iopub.status.idle":"2022-05-25T03:41:19.988424Z","shell.execute_reply.started":"2022-05-25T03:41:19.982190Z","shell.execute_reply":"2022-05-25T03:41:19.987783Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"set(test_missing_only)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:20.639495Z","iopub.execute_input":"2022-05-25T03:41:20.640424Z","iopub.status.idle":"2022-05-25T03:41:20.646380Z","shell.execute_reply.started":"2022-05-25T03:41:20.640377Z","shell.execute_reply":"2022-05-25T03:41:20.645749Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"#### Discrete Variables","metadata":{}},{"cell_type":"code","source":"msno.matrix(df_train[DISCRETE])","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:21.289808Z","iopub.execute_input":"2022-05-25T03:41:21.290105Z","iopub.status.idle":"2022-05-25T03:41:21.877187Z","shell.execute_reply.started":"2022-05-25T03:41:21.290071Z","shell.execute_reply":"2022-05-25T03:41:21.875807Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"msno.matrix(df_test[DISCRETE])","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:21.943167Z","iopub.execute_input":"2022-05-25T03:41:21.944074Z","iopub.status.idle":"2022-05-25T03:41:22.460858Z","shell.execute_reply.started":"2022-05-25T03:41:21.944018Z","shell.execute_reply":"2022-05-25T03:41:22.459854Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"#### Continuous Variables","metadata":{}},{"cell_type":"code","source":"msno.matrix(df_train[CONTINUOUS])","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:22.607471Z","iopub.execute_input":"2022-05-25T03:41:22.607785Z","iopub.status.idle":"2022-05-25T03:41:23.309711Z","shell.execute_reply.started":"2022-05-25T03:41:22.607733Z","shell.execute_reply":"2022-05-25T03:41:23.308659Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"msno.matrix(df_test[CONTINUOUS])","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:23.311468Z","iopub.execute_input":"2022-05-25T03:41:23.311814Z","iopub.status.idle":"2022-05-25T03:41:23.870191Z","shell.execute_reply.started":"2022-05-25T03:41:23.311735Z","shell.execute_reply":"2022-05-25T03:41:23.869431Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"#### Nominal Variables","metadata":{}},{"cell_type":"code","source":"msno.matrix(df_train[NOMINAL])","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:23.907799Z","iopub.execute_input":"2022-05-25T03:41:23.908250Z","iopub.status.idle":"2022-05-25T03:41:24.520947Z","shell.execute_reply.started":"2022-05-25T03:41:23.908216Z","shell.execute_reply":"2022-05-25T03:41:24.520067Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"msno.matrix(df_test[NOMINAL])","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:24.564594Z","iopub.execute_input":"2022-05-25T03:41:24.565418Z","iopub.status.idle":"2022-05-25T03:41:25.170343Z","shell.execute_reply.started":"2022-05-25T03:41:24.565360Z","shell.execute_reply":"2022-05-25T03:41:25.169330Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"#### Ordinal Variables","metadata":{}},{"cell_type":"code","source":"msno.matrix(df_train[ORDINAL])","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:25.213895Z","iopub.execute_input":"2022-05-25T03:41:25.214315Z","iopub.status.idle":"2022-05-25T03:41:25.834666Z","shell.execute_reply.started":"2022-05-25T03:41:25.214265Z","shell.execute_reply":"2022-05-25T03:41:25.833792Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"msno.matrix(df_test[ORDINAL])","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:25.911744Z","iopub.execute_input":"2022-05-25T03:41:25.912198Z","iopub.status.idle":"2022-05-25T03:41:26.529258Z","shell.execute_reply.started":"2022-05-25T03:41:25.912164Z","shell.execute_reply":"2022-05-25T03:41:26.528237Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"### 1.2.3 Deal with Missing Values\nAlthough we found that some variables have too many missing values (PoolQC, MiscFeature, Alley), we just keep them here in case there are other analysis related to them later. If a variable has little information, it can be eliminated by outlier detection or using feature selection techniques before modelling anyway.\n\nTo avoid data leakage, here we do data imputation only based on train set, which also means that we assume that test set has the same data distribution as train set.\n\n- test_missing_only: not a lot of missing values for each variable, but cannot drop the rows, try to impute\n    - impute with 0: \n        - BsmtFinSF1, BsmtFinSF2, BsmtFullBath, BsmtHalfBath, BsmtUnfSF, TotalBsmtSF\n        - GarageArea, GarageCars\n    - impute with mode: \n        - Exterior1st, Exterior2nd\n        - Functional, KitchenQual, MSZoning, SaleType, Utilities\n        \n- train_missing_only\n    - impute with mode: \n        - Electrical\n\n- train_test_missing_both\n    - impute with 'None': \n        - Alley, Fence, FireplaceQu, PoolQC, MiscFeature\n        - BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2, BsmtQual\n        - GarageCond, GarageFinish, GarageQual, GarageType, GarageYrBlt\n    - impute with median: \n        - LotFrontage\n        - MasVnrArea\n    - impute with mode:\n        - MasVnrType","metadata":{}},{"cell_type":"markdown","source":"#### Basement-related Variables Error\n**Note**: From the above matrix plots built with missingno, we can see that there may be some data errors in basement-related variables: \n- If a house doesn't have a basement, all the basement-related variables should be NaN. However, we can check that some samples don't satisfy this rule. We can fix them with the mode using other basement-related variables.\n- Actually I guess there won't be much effect, but since we saw this issue, we can fix it here.\n    - impute id=949 in df_train with BsmtExposure='No'\n    - impute id=333 in df_train with BsmtFinType2='Unf'","metadata":{}},{"cell_type":"code","source":"bsmt_related_vars = ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtFullBath', 'BsmtHalfBath', 'BsmtUnfSF', 'TotalBsmtSF', \n                     'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'BsmtQual']\ndf_train[bsmt_related_vars].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:26.571862Z","iopub.execute_input":"2022-05-25T03:41:26.572172Z","iopub.status.idle":"2022-05-25T03:41:26.583983Z","shell.execute_reply.started":"2022-05-25T03:41:26.572136Z","shell.execute_reply":"2022-05-25T03:41:26.583095Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"df_train[bsmt_related_vars][df_train['BsmtCond'].notnull() & df_train['BsmtExposure'].isnull()]","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:27.243915Z","iopub.execute_input":"2022-05-25T03:41:27.244431Z","iopub.status.idle":"2022-05-25T03:41:27.261798Z","shell.execute_reply.started":"2022-05-25T03:41:27.244379Z","shell.execute_reply":"2022-05-25T03:41:27.260622Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"df_train[bsmt_related_vars][(df_train['BsmtCond']=='TA') & (df_train['BsmtFinType1']=='Unf') & \n                            (df_train['BsmtFinType2']=='Unf') & (df_train['BsmtQual']=='Gd')]['BsmtExposure'].mode()[0]","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:27.894107Z","iopub.execute_input":"2022-05-25T03:41:27.894488Z","iopub.status.idle":"2022-05-25T03:41:27.911385Z","shell.execute_reply.started":"2022-05-25T03:41:27.894448Z","shell.execute_reply":"2022-05-25T03:41:27.910389Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"df_train[bsmt_related_vars][df_train['BsmtCond'].notnull() & df_train['BsmtFinType2'].isnull()]","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:28.549685Z","iopub.execute_input":"2022-05-25T03:41:28.550850Z","iopub.status.idle":"2022-05-25T03:41:28.567139Z","shell.execute_reply.started":"2022-05-25T03:41:28.550767Z","shell.execute_reply":"2022-05-25T03:41:28.566036Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"df_train[bsmt_related_vars][(df_train['BsmtCond']=='TA') & (df_train['BsmtFinType1']=='GLQ') & \n                            (df_train['BsmtExposure']=='No') & (df_train['BsmtQual']=='Gd')]['BsmtFinType2'].mode()[0]","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:29.197385Z","iopub.execute_input":"2022-05-25T03:41:29.197666Z","iopub.status.idle":"2022-05-25T03:41:29.210426Z","shell.execute_reply.started":"2022-05-25T03:41:29.197637Z","shell.execute_reply":"2022-05-25T03:41:29.209575Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"#### LotFrontage\n**Note**: LotFrontage is a little bit special since it has many missing values and it may not be very accurate to impute all of them with median. A more reasonable way is to impute them with median in the corresponding neighborhood since we can assume that the lot frontages of different houses in the same neighborhood are the same or close to each other.","metadata":{}},{"cell_type":"code","source":"# aaa = df_train.groupby('Neighborhood')['LotFrontage'].apply(lambda x: x.fillna(x.median()))\n# df_median = df_train.groupby('Neighborhood')['LotFrontage'].median()\n# bbb = df_train['LotFrontage'].fillna(df_train.reset_index().merge(df_median, on='Neighborhood', how='left').set_index('Id')['LotFrontage_y'])\n# sum(aaa==bbb)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:29.857958Z","iopub.execute_input":"2022-05-25T03:41:29.858431Z","iopub.status.idle":"2022-05-25T03:41:29.862114Z","shell.execute_reply.started":"2022-05-25T03:41:29.858383Z","shell.execute_reply":"2022-05-25T03:41:29.860995Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"### 1.2.4 Get Cleaned Data","metadata":{}},{"cell_type":"code","source":"#deal with missing values\ndef data_cleaning(df_train, df_test):\n    clean_train = df_train.copy()\n    clean_test = df_test.copy()\n    \n    #train\n    ##fix id=949 and id=333\n    clean_train.loc[949, 'BsmtExposure'] = clean_train[(clean_train['BsmtQual']=='Gd') & \n                                                       (clean_train['BsmtCond']=='TA') & \n                                                       (clean_train['BsmtFinType1']=='Unf') & \n                                                       (clean_train['BsmtFinType2']=='Unf')]['BsmtExposure'].mode()[0]\n    \n    clean_train.loc[333, 'BsmtFinType2'] = clean_train[(clean_train['BsmtCond']=='TA') & \n                                                       (clean_train['BsmtFinType1']=='GLQ') & \n                                                       (clean_train['BsmtExposure']=='No') & \n                                                       (clean_train['BsmtQual']=='Gd')]['BsmtFinType2'].mode()[0]\n    ##impute with 0\n    clean_train['GarageYrBlt'].fillna(0, inplace=True)\n \n    ##impute with mode\n    for col in ['Electrical', 'MasVnrType']:\n        clean_train[col].fillna(clean_train[col].mode()[0], inplace=True)\n    \n    ##impute with 'None'\n    for col in ['Alley', 'Fence', 'FireplaceQu', 'PoolQC', 'MiscFeature', \n                'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'BsmtQual', \n                'GarageCond', 'GarageFinish', 'GarageQual', 'GarageType']:\n        clean_train[col].fillna('None', inplace=True)\n        \n    ##impute with median\n    clean_train['MasVnrArea'].fillna(clean_train['MasVnrArea'].median(), inplace=True)\n    \n    ##LotFrontage: impute with median in each neighborhood\n    df_median = df_train.groupby('Neighborhood')['LotFrontage'].median()\n    clean_train['LotFrontage'] = clean_train['LotFrontage'].fillna(clean_train.reset_index().merge(df_median, on='Neighborhood', how='left').set_index('Id')['LotFrontage_y'])\n    \n    \n    #test\n    ##impute with 0\n    for col in ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtFullBath', 'BsmtHalfBath', 'BsmtUnfSF', 'TotalBsmtSF', \n                'GarageArea', 'GarageCars', 'GarageYrBlt']:\n        clean_test[col].fillna(0, inplace=True)\n    \n    ##impute with 'None'\n    for col in ['Alley', 'Fence', 'FireplaceQu', 'PoolQC', 'MiscFeature', \n                'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'BsmtQual', \n                'GarageCond', 'GarageFinish', 'GarageQual', 'GarageType']:\n        clean_test[col].fillna('None', inplace=True)\n    \n    ##impute with mode\n    for col in ['Exterior1st', 'Exterior2nd', \n                'Functional', 'KitchenQual', 'MSZoning', 'SaleType', 'Utilities', \n                'MasVnrType']:\n        clean_test[col].fillna(clean_train[col].mode()[0], inplace=True)\n    \n    ##impute with median\n    clean_test['MasVnrArea'].fillna(clean_train['MasVnrArea'].median(), inplace=True)\n    \n    ##LotFrontage: impute with median in each neighborhood\n    clean_test['LotFrontage'] = clean_test['LotFrontage'].fillna(clean_test.reset_index().merge(df_median, on='Neighborhood', how='left').set_index('Id')['LotFrontage_y'])\n\n    return clean_train, clean_test\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:30.710844Z","iopub.execute_input":"2022-05-25T03:41:30.711341Z","iopub.status.idle":"2022-05-25T03:41:30.730581Z","shell.execute_reply.started":"2022-05-25T03:41:30.711288Z","shell.execute_reply":"2022-05-25T03:41:30.729773Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"df_tr, df_te = data_cleaning(df_train, df_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:31.347565Z","iopub.execute_input":"2022-05-25T03:41:31.348414Z","iopub.status.idle":"2022-05-25T03:41:31.446725Z","shell.execute_reply.started":"2022-05-25T03:41:31.348366Z","shell.execute_reply":"2022-05-25T03:41:31.445717Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"print(sum(df_tr.isnull().sum()))\nprint(sum(df_te.isnull().sum()))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:32.000037Z","iopub.execute_input":"2022-05-25T03:41:32.000800Z","iopub.status.idle":"2022-05-25T03:41:32.025181Z","shell.execute_reply.started":"2022-05-25T03:41:32.000738Z","shell.execute_reply":"2022-05-25T03:41:32.024060Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"df_tr[DISCRETE] = df_tr[DISCRETE].astype(np.int64)\ndf_te[DISCRETE] = df_te[DISCRETE].astype(np.int64)\ndf_tr[CONTINUOUS] = df_tr[CONTINUOUS].astype(np.float64)\ndf_te[CONTINUOUS] = df_te[CONTINUOUS].astype(np.float64)\ndf_tr['MSSubClass'] = df_tr['MSSubClass'].astype(str)\ndf_te['MSSubClass'] = df_te['MSSubClass'].astype(str)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:32.645481Z","iopub.execute_input":"2022-05-25T03:41:32.645801Z","iopub.status.idle":"2022-05-25T03:41:32.676714Z","shell.execute_reply.started":"2022-05-25T03:41:32.645745Z","shell.execute_reply":"2022-05-25T03:41:32.675822Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"## 1.3 Variable Dependency\nThere are some internal relationships between variables:\n- GrLivArea = 1stFlrSF + 2ndFlrSF + LowQualFinSF, which is the total area square feet above ground\n- TotalBsmtSF = BsmtFinSF1 + BsmtFinSF2 + BsmtUnfSF, which is the total basement square feet","metadata":{}},{"cell_type":"code","source":"print(sum(df_tr['GrLivArea'] == df_tr['1stFlrSF'] + df_tr['2ndFlrSF'] + df_tr['LowQualFinSF']))\nprint(sum(df_te['GrLivArea'] == df_te['1stFlrSF'] + df_te['2ndFlrSF'] + df_te['LowQualFinSF']))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:33.296458Z","iopub.execute_input":"2022-05-25T03:41:33.296793Z","iopub.status.idle":"2022-05-25T03:41:33.305430Z","shell.execute_reply.started":"2022-05-25T03:41:33.296742Z","shell.execute_reply":"2022-05-25T03:41:33.304794Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"print(sum(df_tr['TotalBsmtSF'] == df_tr['BsmtFinSF1'] + df_tr['BsmtFinSF2'] + df_tr['BsmtUnfSF']))\nprint(sum(df_te['TotalBsmtSF'] == df_te['BsmtFinSF1'] + df_te['BsmtFinSF2'] + df_te['BsmtUnfSF']))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:33.966061Z","iopub.execute_input":"2022-05-25T03:41:33.966522Z","iopub.status.idle":"2022-05-25T03:41:33.976552Z","shell.execute_reply.started":"2022-05-25T03:41:33.966491Z","shell.execute_reply":"2022-05-25T03:41:33.975838Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"#room-related variables don't have such dependency\nprint(sum(df_tr[\"TotRmsAbvGrd\"] == df_tr[\"BedroomAbvGr\"] + df_tr[\"KitchenAbvGr\"] + df_tr[\"FullBath\"]))\nprint(sum(df_te[\"TotRmsAbvGrd\"] == df_te[\"BedroomAbvGr\"] + df_te[\"KitchenAbvGr\"] + df_te[\"FullBath\"]))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:34.623743Z","iopub.execute_input":"2022-05-25T03:41:34.624213Z","iopub.status.idle":"2022-05-25T03:41:34.633743Z","shell.execute_reply.started":"2022-05-25T03:41:34.624180Z","shell.execute_reply":"2022-05-25T03:41:34.633065Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"## 1.4 Target variable: SalePrice\n- SalePrice is not normally distributed, which can be a problem for some regression algorithms\n    - skewness > 1, highly positive skewed\n    - kurtosis > 3, heavy-tailed with outliers\n- Log transformation is needed to reduce the skewness of our original data. (the original data approximately follow a log-normal distribution)","metadata":{}},{"cell_type":"code","source":"df_tr['SalePrice'].describe()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:35.273693Z","iopub.execute_input":"2022-05-25T03:41:35.274150Z","iopub.status.idle":"2022-05-25T03:41:35.284678Z","shell.execute_reply.started":"2022-05-25T03:41:35.274109Z","shell.execute_reply":"2022-05-25T03:41:35.283788Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"print('Skewness: %f' % df_tr['SalePrice'].skew())\nprint('Kurtosis: %f' % df_tr['SalePrice'].kurt())","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:35.921607Z","iopub.execute_input":"2022-05-25T03:41:35.921921Z","iopub.status.idle":"2022-05-25T03:41:35.927689Z","shell.execute_reply.started":"2022-05-25T03:41:35.921888Z","shell.execute_reply":"2022-05-25T03:41:35.927067Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"def dist_prob_plot(s):\n    fig, ax = plt.subplots(1, 2, figsize=(12,4))\n    sns.distplot(s, fit=norm, ax=ax[0])\n    ax[1] = spst.probplot(s, dist=\"norm\", plot=pylab) #Q-Q plot","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:36.569929Z","iopub.execute_input":"2022-05-25T03:41:36.570776Z","iopub.status.idle":"2022-05-25T03:41:36.576517Z","shell.execute_reply.started":"2022-05-25T03:41:36.570690Z","shell.execute_reply":"2022-05-25T03:41:36.575838Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"dist_prob_plot(df_tr['SalePrice'])","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:37.224029Z","iopub.execute_input":"2022-05-25T03:41:37.224345Z","iopub.status.idle":"2022-05-25T03:41:37.666359Z","shell.execute_reply.started":"2022-05-25T03:41:37.224311Z","shell.execute_reply":"2022-05-25T03:41:37.665412Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"#after log transformation\ndist_prob_plot(np.log1p(df_tr['SalePrice']))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:38.222101Z","iopub.execute_input":"2022-05-25T03:41:38.222386Z","iopub.status.idle":"2022-05-25T03:41:38.641120Z","shell.execute_reply.started":"2022-05-25T03:41:38.222357Z","shell.execute_reply":"2022-05-25T03:41:38.640154Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"## 1.5 Variable Distributions","metadata":{}},{"cell_type":"markdown","source":"### 1.5.1 Simple Visualizations","metadata":{}},{"cell_type":"code","source":"def numerical_plot(df, feature_list, row_num, col_num, figsize=(20,20)):\n    fig, axes = plt.subplots(row_num, col_num, figsize=figsize)\n    for i, col_name in enumerate(feature_list):\n        ax = axes[int(i/col_num), i%col_num]\n        sns.distplot(df[col_name], fit=norm, ax=ax)\n        ax.set_title(col_name)\n    plt.tight_layout()\n    \ndef categorical_plot(df, feature_list, row_num, col_num, figsize=(20,20), kind='bar'):\n    fig, axes = plt.subplots(row_num, col_num, figsize=figsize)\n    for i, col_name in enumerate(feature_list):\n        ax = axes[int(i/col_num), i%col_num]\n        df[col_name].value_counts(sort=False, dropna=False).plot(kind=kind, ax=ax)\n        ax.set_title(col_name)\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:39.223992Z","iopub.execute_input":"2022-05-25T03:41:39.224268Z","iopub.status.idle":"2022-05-25T03:41:39.234025Z","shell.execute_reply.started":"2022-05-25T03:41:39.224240Z","shell.execute_reply":"2022-05-25T03:41:39.233288Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"numerical_plot(df_tr, NUMERICAL, 6, 6, figsize=(20,20))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:39.866739Z","iopub.execute_input":"2022-05-25T03:41:39.867367Z","iopub.status.idle":"2022-05-25T03:41:48.202469Z","shell.execute_reply.started":"2022-05-25T03:41:39.867331Z","shell.execute_reply":"2022-05-25T03:41:48.201337Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"categorical_plot(df_tr, CATEGORICAL, 8, 6, figsize=(20,30), kind='bar')","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:48.204394Z","iopub.execute_input":"2022-05-25T03:41:48.204669Z","iopub.status.idle":"2022-05-25T03:41:56.050522Z","shell.execute_reply.started":"2022-05-25T03:41:48.204635Z","shell.execute_reply":"2022-05-25T03:41:56.049345Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"### 1.5.2 Normality of Continuous Variables\nIn regression models, we want each variable to be normally distributed. If not, we can consider to apply [Box-Cox transformation](https://www.statisticshowto.com/box-cox-transformation/) on such variables whose values are always positive.","metadata":{}},{"cell_type":"code","source":"pt_cols = list(df_tr[CONTINUOUS].min()[df_tr[CONTINUOUS].min()>0].index)\npt = PowerTransformer(method='box-cox', standardize=False)\npt.fit(df_tr[pt_cols])\nfor i in range(len(pt_cols)):\n    print(\"{} lambda={}\".format(pt_cols[i], pt.lambdas_[i]))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:56.052438Z","iopub.execute_input":"2022-05-25T03:41:56.053408Z","iopub.status.idle":"2022-05-25T03:41:56.087318Z","shell.execute_reply.started":"2022-05-25T03:41:56.053358Z","shell.execute_reply":"2022-05-25T03:41:56.086226Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"dict_transformed = {}\nfor i in range(len(pt_cols)):\n    dict_transformed[pt_cols[i]] = pt.transform(df_tr[pt_cols])[:,i]\ndf_transformed = pd.DataFrame(dict_transformed, index=df_tr.index)\n\nfor col in pt_cols:\n    dist_prob_plot(df_transformed[col])","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:56.090212Z","iopub.execute_input":"2022-05-25T03:41:56.090567Z","iopub.status.idle":"2022-05-25T03:41:57.753347Z","shell.execute_reply.started":"2022-05-25T03:41:56.090519Z","shell.execute_reply":"2022-05-25T03:41:57.752028Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"## 1.6 Outliers\nAccording to the original paper, the author told us that there are some outliers in the dataset. In the above probability plots, you may have already found some the outliers. We can plot a scatter plot of SalePrice versus GrLivArea as a confirmation.\n\nNotice that 4 houses with more than 4000 square feet from the train set may be outliers. \n- 2 houses from Edwards neighborhood are very large but the sales are partial sales, which may not represent actual market values of the houses\n- 2 houses from NoRidge neighborhood are priced extremely high","metadata":{}},{"cell_type":"code","source":"plt.scatter(df_tr['GrLivArea'], df_tr['SalePrice'])\nplt.xlabel('GrLivArea')\nplt.ylabel('SalePrice')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:57.754624Z","iopub.execute_input":"2022-05-25T03:41:57.754893Z","iopub.status.idle":"2022-05-25T03:41:57.960186Z","shell.execute_reply.started":"2022-05-25T03:41:57.754860Z","shell.execute_reply":"2022-05-25T03:41:57.959360Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"#check them in detail\ndf_tr[df_tr['GrLivArea']>4000]","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:57.961282Z","iopub.execute_input":"2022-05-25T03:41:57.961882Z","iopub.status.idle":"2022-05-25T03:41:58.030108Z","shell.execute_reply.started":"2022-05-25T03:41:57.961845Z","shell.execute_reply":"2022-05-25T03:41:58.029078Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"## 1.7 Correlations\nHere we simply check the correlations between each variable and the target variable","metadata":{}},{"cell_type":"markdown","source":"### 1.7.1 Simple Visualizations\n- Numerical variables: scatter plot\n- Categorical variables: box plot\n\n**Some interesting insights**:\n- Some continuous variables have a quite share of zero values, e.g. 2ndFlrSF, which suggests that we can try to add an indicator variable and see if it can be a better feature than the original one. \n- Some categorical variables contain much information about SalePrice since the SalePrice varies a lot in different categories, e.g. Neighborhood.","metadata":{}},{"cell_type":"code","source":"def var_scatter_plot(df, feature_list, row_num, col_num, figsize=(20,20)):\n    fig, axes = plt.subplots(row_num, col_num, figsize=figsize)\n    for i, col_name in enumerate(feature_list):\n        ax = axes[int(i/col_num), i%col_num]\n        sns.scatterplot(x=col_name, y='SalePrice', data=df[feature_list + ['SalePrice']], ax=ax)\n        ax.set_title(col_name)\n    plt.tight_layout()\n\ndef var_box_plot(df, feature_list, row_num, col_num, figsize=(20,20)):\n    fig, axes = plt.subplots(row_num, col_num, figsize=figsize)\n    for i, col_name in enumerate(feature_list):\n        ax = axes[int(i/col_num), i%col_num]\n        sns.boxplot(x=col_name, y='SalePrice', data=df[feature_list + ['SalePrice']], ax=ax)\n        ax.set_title(col_name)\n        ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:58.031363Z","iopub.execute_input":"2022-05-25T03:41:58.031589Z","iopub.status.idle":"2022-05-25T03:41:58.043301Z","shell.execute_reply.started":"2022-05-25T03:41:58.031562Z","shell.execute_reply":"2022-05-25T03:41:58.042354Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"var_scatter_plot(df_tr, NUMERICAL, 6, 6, figsize=(20,20))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:41:58.044541Z","iopub.execute_input":"2022-05-25T03:41:58.044915Z","iopub.status.idle":"2022-05-25T03:42:03.929062Z","shell.execute_reply.started":"2022-05-25T03:41:58.044879Z","shell.execute_reply":"2022-05-25T03:42:03.928040Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"var_box_plot(df_tr, CATEGORICAL, 8, 6, figsize=(20,30))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:03.930526Z","iopub.execute_input":"2022-05-25T03:42:03.930898Z","iopub.status.idle":"2022-05-25T03:42:15.640352Z","shell.execute_reply.started":"2022-05-25T03:42:03.930856Z","shell.execute_reply":"2022-05-25T03:42:15.639177Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"### 1.7.2 Correlation Coefficients for Numerical Variables\n- There are 2 kinds of correlation coefficients for numerical variables: [Pearson and Spearman](https://towardsdatascience.com/clearly-explained-pearson-v-s-spearman-correlation-coefficient-ada2f473b8). Both coefficients can only give linear correlations.\n    - For continuous variables: Pearson's correlation\n    - For discrete variables: Spearman's rank correlation\n- We can do this again later after data preparation part to give suggestions on feature selection. \n\n**Some highly-correlated pairs (coefficient > 0.8)**:\n- TotalBsmtSF, 1stFlrSF: Basements may have generally the same area as the first floor\n- YearBuilt, GarageYrBlt: Garages seem to be built in the same year as houses\n- GarageArea, GarageCars: Garage area is highly correlated with number of cars which makes sense\n- TotRmsAbvGrd, GrLivArea: Number of rooms above grade is highly correlated with living area above grade (ground)\n\n**Other insights**:\n- GrLivArea seems to have the highest correlation with SalePrice in all the numerical variables.","metadata":{}},{"cell_type":"code","source":"def correlation_plot(df, feature_list, method='pearson', figsize=(24,16)):\n    fig, ax = plt.subplots(figsize=figsize)\n    sns.heatmap(df[feature_list + ['SalePrice']].corr(method=method), vmax=0.8, annot=True, cmap='Blues', ax=ax)\n    if method=='pearson':\n        plt.title(\"Pearson's Correlation\")\n    elif method=='spearman':\n        plt.title(\"Spearman's Rank Correlation\")","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:15.644670Z","iopub.execute_input":"2022-05-25T03:42:15.645043Z","iopub.status.idle":"2022-05-25T03:42:15.653667Z","shell.execute_reply.started":"2022-05-25T03:42:15.645001Z","shell.execute_reply":"2022-05-25T03:42:15.652462Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"correlation_plot(df_tr, CONTINUOUS, 'pearson', (14,10))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:15.655238Z","iopub.execute_input":"2022-05-25T03:42:15.655606Z","iopub.status.idle":"2022-05-25T03:42:17.602493Z","shell.execute_reply.started":"2022-05-25T03:42:15.655559Z","shell.execute_reply":"2022-05-25T03:42:17.601215Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"correlation_plot(df_tr, DISCRETE, 'spearman', (14,10))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:17.604156Z","iopub.execute_input":"2022-05-25T03:42:17.604477Z","iopub.status.idle":"2022-05-25T03:42:18.837679Z","shell.execute_reply.started":"2022-05-25T03:42:17.604438Z","shell.execute_reply":"2022-05-25T03:42:18.836672Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"#DISCRETE+CONTINUOUS\ncorrelation_plot(df_tr, NUMERICAL, 'spearman', (24,16))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:18.838971Z","iopub.execute_input":"2022-05-25T03:42:18.839229Z","iopub.status.idle":"2022-05-25T03:42:24.279291Z","shell.execute_reply.started":"2022-05-25T03:42:18.839200Z","shell.execute_reply":"2022-05-25T03:42:24.278271Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"### 1.7.3 Get Some Insights Between Categorical Variables and GrLivArea\n- Here we can also do some bivariate analysis between categorical and numerical variables as well. \n- As an example, we check if there are some relationships between each nominal variable and the size of a house represented by GrLivArea.\n    - However, it seems that there aren't many new insights here.\n","metadata":{}},{"cell_type":"code","source":"# def GrLivArea_scatter_plot(df, feature_list, row_num, col_num, figsize=(24,16)):\n#     fig, axes = plt.subplots(row_num, col_num, figsize=figsize)\n#     for i, col_name in enumerate(feature_list):\n#         ax = axes[int(i/col_num), i%col_num]\n#         sns.scatterplot(x='GrLivArea', y='SalePrice', hue=col_name, s=15, data=df, ax=ax)\n#     plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:24.280538Z","iopub.execute_input":"2022-05-25T03:42:24.281027Z","iopub.status.idle":"2022-05-25T03:42:24.284998Z","shell.execute_reply.started":"2022-05-25T03:42:24.280981Z","shell.execute_reply":"2022-05-25T03:42:24.284179Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# GrLivArea_scatter_plot(df_tr, NOMINAL, 8, 3, figsize=(24,64))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:24.286546Z","iopub.execute_input":"2022-05-25T03:42:24.286897Z","iopub.status.idle":"2022-05-25T03:42:24.304425Z","shell.execute_reply.started":"2022-05-25T03:42:24.286860Z","shell.execute_reply":"2022-05-25T03:42:24.303634Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":"# 2 Data Preparation\nWhat we have already done:\n- dealt with missing values and feature types\n- checked the distributions of variables\n- identified outliers\n\nWhat needs to be done next:\n- remove outliers\n- feature engineering\n    - create new features\n    - deal with multicollearity by removing redundant variables\n- apply box-cox transformation on some continuous variables\n- categorical variables encoding\n    - one-hot for nominal variables\n    - ordered label for ordinal variables\n- standardization (mean 0 and std 1), but not including dummy variables\n- naive feature selection / dimension reduction","metadata":{}},{"cell_type":"markdown","source":"## 2.1 Remove Outliers\n- Here we just use a naive way according to the suggestion in the original paper.\n- If you want to check other outliers, you can use 3$\\sigma$ rules.","metadata":{}},{"cell_type":"code","source":"def remove_outliers(df_tr):\n    df = df_tr.copy()\n    df = df[df['GrLivArea']<=4000]\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:24.305992Z","iopub.execute_input":"2022-05-25T03:42:24.306277Z","iopub.status.idle":"2022-05-25T03:42:24.320051Z","shell.execute_reply.started":"2022-05-25T03:42:24.306245Z","shell.execute_reply":"2022-05-25T03:42:24.318785Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"df_tr1 = remove_outliers(df_tr)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:24.321623Z","iopub.execute_input":"2022-05-25T03:42:24.322515Z","iopub.status.idle":"2022-05-25T03:42:24.340770Z","shell.execute_reply.started":"2022-05-25T03:42:24.322461Z","shell.execute_reply":"2022-05-25T03:42:24.340012Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"## 2.2 Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"### 2.2.1 Create New Variables","metadata":{}},{"cell_type":"code","source":"#feature engineering (create new features, remove multicollinearity)\ndef create_new_variables(df_tr):\n    df = df_tr.copy()\n    df['TotalSF'] = df['GrLivArea'] + df['TotalBsmtSF']\n    df['TotalPorchSF'] = df['3SsnPorch'] + df['EnclosedPorch'] + df['OpenPorchSF'] + df['ScreenPorch'] + df['WoodDeckSF']\n    df['TotalBath'] = df['FullBath'] + 0.5 * df['HalfBath'] + df['BsmtFullBath'] + 0.5 * df['BsmtHalfBath']\n    \n    df['Has2ndFlr'] = df['2ndFlrSF'].apply(lambda x: 0 if x==0 else 1)\n    df['HasBsmt'] = df['TotalBsmtSF'].apply(lambda x: 0 if x==0 else 1)\n    df['HasFireplace'] = df['Fireplaces'].apply(lambda x: 0 if x==0 else 1)\n    df['HasGarage'] = df['GarageArea'].apply(lambda x: 0 if x==0 else 1)\n    df['HasPorch'] = df['TotalPorchSF'].apply(lambda x: 0 if x==0 else 1)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:24.342021Z","iopub.execute_input":"2022-05-25T03:42:24.342522Z","iopub.status.idle":"2022-05-25T03:42:24.354298Z","shell.execute_reply.started":"2022-05-25T03:42:24.342488Z","shell.execute_reply":"2022-05-25T03:42:24.353157Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"NEW_VARIABLES = ['TotalSF', 'TotalPorchSF', 'TotalBath', 'Has2ndFlr', 'HasBsmt', \n                 'HasFireplace', 'HasGarage', 'HasPorch']\ndf_tr2 = create_new_variables(df_tr1)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:24.355796Z","iopub.execute_input":"2022-05-25T03:42:24.356504Z","iopub.status.idle":"2022-05-25T03:42:24.383173Z","shell.execute_reply.started":"2022-05-25T03:42:24.356450Z","shell.execute_reply":"2022-05-25T03:42:24.382460Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"### 2.2.2 Deal with Multicollearity by Removing Redundant Numerical Variables\nObvious linear relationships:\n- GrLivArea = 1stFlrSF + 2ndFlrSF + LowQualFinSF\n- TotalBsmtSF = BsmtFinSF1 + BsmtFinSF2 + BsmtUnfSF\n- TotalBath = FullBath + 0.5 * HalfBath + BsmtFullBath + 0.5 * BsmtHalfBath\n- TotalSF = GrLivArea + TotalBsmtSF\n- TotalPorchSF = 3SsnPorch + EnclosedPorch + OpenPorchSF + ScreenPorch + WoodDeckSF\n\nVariable pairs with Pearson's coefficient or Spearman's coefficient > 0.8: \n- high_corr_pairs\n\nRemove redundant variables based on their correlations with SalePrice.","metadata":{}},{"cell_type":"code","source":"p_corr = df_tr2[NUMERICAL+NEW_VARIABLES+['SalePrice']].corr(method='pearson')\ns_corr = df_tr2[NUMERICAL+NEW_VARIABLES+['SalePrice']].corr(method='spearman')","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:24.384546Z","iopub.execute_input":"2022-05-25T03:42:24.385453Z","iopub.status.idle":"2022-05-25T03:42:24.412708Z","shell.execute_reply.started":"2022-05-25T03:42:24.385416Z","shell.execute_reply":"2022-05-25T03:42:24.411872Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"def high_corr_pairs(p_corr, s_corr):\n    pairs = []\n    for i in range(1, len(p_corr)):\n        for j in range(0, i):\n            p = abs(p_corr.iloc[i, j])\n            s = abs(s_corr.iloc[i, j])\n            if s>0.8 or p>0.8:\n                pairs.append((p_corr.index[i], p_corr.columns[j]))\n                \n    return pairs\n                \nhigh_corr_pairs(p_corr, s_corr)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:24.414067Z","iopub.execute_input":"2022-05-25T03:42:24.414831Z","iopub.status.idle":"2022-05-25T03:42:24.488413Z","shell.execute_reply.started":"2022-05-25T03:42:24.414788Z","shell.execute_reply":"2022-05-25T03:42:24.487289Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# p_corr.loc['SalePrice',:]","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:24.490021Z","iopub.execute_input":"2022-05-25T03:42:24.490461Z","iopub.status.idle":"2022-05-25T03:42:24.496062Z","shell.execute_reply.started":"2022-05-25T03:42:24.490411Z","shell.execute_reply":"2022-05-25T03:42:24.495044Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"# s_corr.loc['SalePrice',:]","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:24.497745Z","iopub.execute_input":"2022-05-25T03:42:24.498742Z","iopub.status.idle":"2022-05-25T03:42:24.510300Z","shell.execute_reply.started":"2022-05-25T03:42:24.498692Z","shell.execute_reply":"2022-05-25T03:42:24.509361Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"def remove_multicollinearity(df_tr):\n    df = df_tr.copy()\n    remove_cols = ['GarageYrBlt', 'GrLivArea', 'GarageArea', '1stFlrSF', 'TotalBsmtSF', \n                   'Fireplaces', 'Has2ndFlr', 'BsmtHalfBath', '3SsnPorch']\n    \n    return df.drop(remove_cols, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:24.511802Z","iopub.execute_input":"2022-05-25T03:42:24.512256Z","iopub.status.idle":"2022-05-25T03:42:24.525084Z","shell.execute_reply.started":"2022-05-25T03:42:24.512208Z","shell.execute_reply":"2022-05-25T03:42:24.524118Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"df_tr3 = remove_multicollinearity(df_tr2)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:24.526514Z","iopub.execute_input":"2022-05-25T03:42:24.526835Z","iopub.status.idle":"2022-05-25T03:42:24.543946Z","shell.execute_reply.started":"2022-05-25T03:42:24.526799Z","shell.execute_reply":"2022-05-25T03:42:24.542934Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"#updata feature lists\n\n#continuous\nCONTINUOUS_1 = CONTINUOUS + ['TotalSF', 'TotalPorchSF', 'TotalBath']\nfor col in ['GrLivArea', 'GarageArea', '1stFlrSF', 'TotalBsmtSF', '3SsnPorch']:\n    CONTINUOUS_1.remove(col)\n\n#discrete\nDISCRETE_1 = DISCRETE + ['Has2ndFlr', 'HasBsmt', 'HasFireplace', 'HasGarage', 'HasPorch']\nfor col in ['GarageYrBlt', 'Fireplaces', 'Has2ndFlr', 'BsmtHalfBath']:\n    DISCRETE_1.remove(col)\n\nNUMERICAL_1 = CONTINUOUS_1 + DISCRETE_1","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:24.545212Z","iopub.execute_input":"2022-05-25T03:42:24.545911Z","iopub.status.idle":"2022-05-25T03:42:24.562383Z","shell.execute_reply.started":"2022-05-25T03:42:24.545871Z","shell.execute_reply":"2022-05-25T03:42:24.561617Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":"## 2.3 Variable Transformations\nTarget variable: log transformation\n\nFeature variables: Box-Cox transformation\n- Notice that although TotalBath is float typed, its values are actually discrete, so we don't apply Box-Cox transformation on it.\n- To make the transformation more interpretable, based on the values of lambda and [common Box-Cox transformations](https://www.statisticshowto.com/box-cox-transformation/), we apply log transformation on LotArea, square root transformation on LotFrontage and TotalSF.","metadata":{}},{"cell_type":"code","source":"pt_cols = list(df_tr3[CONTINUOUS_1].min()[df_tr3[CONTINUOUS_1].min()>0].index)\npt = PowerTransformer(method='box-cox', standardize=False)\npt.fit(df_tr3[pt_cols])\nfor i in range(len(pt_cols)):\n    print(\"{} lambda={}\".format(pt_cols[i], round(pt.lambdas_[i], 2)))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:24.563574Z","iopub.execute_input":"2022-05-25T03:42:24.564025Z","iopub.status.idle":"2022-05-25T03:42:24.600562Z","shell.execute_reply.started":"2022-05-25T03:42:24.563987Z","shell.execute_reply":"2022-05-25T03:42:24.599532Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"def box_cox_transformation(df_tr):\n    df = df_tr.copy()\n    if 'SalePrice' in df.columns:\n        df['SalePrice'] = np.log1p(df['SalePrice'])\n        \n    df['LotArea'] = np.log1p(df['LotArea'])\n    df['LotFrontage'] = np.sqrt(df['LotFrontage'])\n    df['TotalSF'] = np.sqrt(df['TotalSF'])\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:24.606225Z","iopub.execute_input":"2022-05-25T03:42:24.606829Z","iopub.status.idle":"2022-05-25T03:42:24.613859Z","shell.execute_reply.started":"2022-05-25T03:42:24.606781Z","shell.execute_reply":"2022-05-25T03:42:24.612850Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"df_tr4 = box_cox_transformation(df_tr3)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:24.615609Z","iopub.execute_input":"2022-05-25T03:42:24.616328Z","iopub.status.idle":"2022-05-25T03:42:24.629737Z","shell.execute_reply.started":"2022-05-25T03:42:24.616275Z","shell.execute_reply":"2022-05-25T03:42:24.628871Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"## 2.4 Categorical Encoding\n- Ordinal variables: Ordinal encoding\n- Nominal variables: One-Hot encoding","metadata":{}},{"cell_type":"code","source":"tr_a = box_cox_transformation(\n    remove_multicollinearity(\n        create_new_variables(\n            remove_outliers(df_tr)\n        )\n    )\n)\n\n#don't apply remove_outliers on test set\nte_a = box_cox_transformation(\n    remove_multicollinearity(\n        create_new_variables(df_te)\n    )\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:24.631417Z","iopub.execute_input":"2022-05-25T03:42:24.632251Z","iopub.status.idle":"2022-05-25T03:42:24.682024Z","shell.execute_reply.started":"2022-05-25T03:42:24.632182Z","shell.execute_reply":"2022-05-25T03:42:24.680960Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"ordinal_map = {'BsmtQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'None':0},\n               'BsmtCond':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'None':0},\n               'BsmtExposure':{'Gd':4, 'Av':3, 'Mn':2, 'No':1, 'None':0},\n               'BsmtFinType1':{'GLQ':6, 'ALQ':5, 'BLQ':4, 'Rec':3, 'LwQ':2, 'Unf':1, 'None':0},\n               'BsmtFinType2':{'GLQ':6, 'ALQ':5, 'BLQ':4, 'Rec':3, 'LwQ':2, 'Unf':1, 'None':0},\n               'ExterQual':{'Ex':4, 'Gd':3, 'TA':2, 'Fa':1, 'Po':0},\n               'ExterCond':{'Ex':4, 'Gd':3, 'TA':2, 'Fa':1, 'Po':0},\n               'Electrical':{'SBrkr':4, 'FuseF':3, 'FuseA':2, 'FuseP':1, 'Mix':0},\n               'Functional':{'Typ':7, 'Min1':6, 'Min2':5, 'Mod':4, 'Maj1':3, 'Maj2':2, 'Sev':1, 'Sal':0},\n               'FireplaceQu':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'None':0},\n               'Fence':{'GdPrv':4, 'MnPrv':3, 'GdWo':2, 'MnWw':1, 'None':0},\n               'GarageFinish':{'Fin':3, 'RFn':2, 'Unf':1, 'None':0},\n               'GarageQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'None':0},\n               'GarageCond':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'None':0},\n               'HeatingQC':{'Ex':4, 'Gd':3, 'TA':2, 'Fa':1, 'Po':0},\n               'KitchenQual':{'Ex':4, 'Gd':3, 'TA':2, 'Fa':1, 'Po':0},\n               'LotShape':{'Reg':3, 'IR1':2, 'IR2':1, 'IR3':0},\n               'LandSlope':{'Gtl':2, 'Mod':1, 'Sev':0},\n               'PavedDrive':{'Y':2, 'P':1, 'N':0},\n               'PoolQC':{'Ex':4, 'Gd':3, 'TA':2, 'Fa':1, 'None':0},\n               'Utilities':{'AllPub':3, 'NoSewr':2, 'NoSeWa':1, 'ELO':0}\n              }\n\n#some categories only exist in test set, so we set handle_unknown='ignore'\none_hot = OneHotEncoder(handle_unknown='ignore').fit(tr_a[NOMINAL])","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:24.683222Z","iopub.execute_input":"2022-05-25T03:42:24.683449Z","iopub.status.idle":"2022-05-25T03:42:24.707466Z","shell.execute_reply.started":"2022-05-25T03:42:24.683420Z","shell.execute_reply":"2022-05-25T03:42:24.706642Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"def categorical_encoding(df_tr, ordinal_map, one_hot, NOMINAL):\n    df = df_tr.copy()\n    #ordinal encoding\n    for col in ordinal_map.keys():\n        df[col] = df[col].map(ordinal_map[col])\n    \n    #one-hot encoding\n    new_feature_names = one_hot.get_feature_names(NOMINAL)\n    one_hot_df = pd.DataFrame(one_hot.transform(df[NOMINAL]).toarray(), columns=new_feature_names, index=df.index)\n    df = pd.concat([df.drop(NOMINAL, axis=1), one_hot_df], axis=1)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:24.708609Z","iopub.execute_input":"2022-05-25T03:42:24.709154Z","iopub.status.idle":"2022-05-25T03:42:24.722033Z","shell.execute_reply.started":"2022-05-25T03:42:24.709117Z","shell.execute_reply":"2022-05-25T03:42:24.721047Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"tr_b = categorical_encoding(tr_a, ordinal_map, one_hot, NOMINAL)\nte_b = categorical_encoding(te_a, ordinal_map, one_hot, NOMINAL)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:24.723243Z","iopub.execute_input":"2022-05-25T03:42:24.723482Z","iopub.status.idle":"2022-05-25T03:42:24.842485Z","shell.execute_reply.started":"2022-05-25T03:42:24.723453Z","shell.execute_reply":"2022-05-25T03:42:24.841305Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"print(tr_b.shape, te_b.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:24.844454Z","iopub.execute_input":"2022-05-25T03:42:24.844769Z","iopub.status.idle":"2022-05-25T03:42:24.850950Z","shell.execute_reply.started":"2022-05-25T03:42:24.844720Z","shell.execute_reply":"2022-05-25T03:42:24.849928Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"markdown","source":"## 2.5 Standardization\n- Ignoring dummy variables, we apply standardization on numerical variables and ordinal variables.","metadata":{}},{"cell_type":"code","source":"tr_b[NUMERICAL_1+ORDINAL].describe()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:24.852225Z","iopub.execute_input":"2022-05-25T03:42:24.852485Z","iopub.status.idle":"2022-05-25T03:42:25.045816Z","shell.execute_reply.started":"2022-05-25T03:42:24.852453Z","shell.execute_reply":"2022-05-25T03:42:25.044807Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"tr_b_X = tr_b.loc[:, tr_b.columns != 'SalePrice']\ntrain_y = tr_b['SalePrice']\n\nscalar = StandardScaler()\nscalar.fit(tr_b_X[NUMERICAL_1+ORDINAL])","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:25.047307Z","iopub.execute_input":"2022-05-25T03:42:25.047558Z","iopub.status.idle":"2022-05-25T03:42:25.062962Z","shell.execute_reply.started":"2022-05-25T03:42:25.047526Z","shell.execute_reply":"2022-05-25T03:42:25.062246Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"def standardization(df_tr, scalar, NUMERICAL_1, ORDINAL):\n    df = df_tr.copy()\n    scale_X = scalar.transform(df[NUMERICAL_1+ORDINAL])\n    scale_df = pd.DataFrame(scale_X, columns=NUMERICAL_1+ORDINAL, index=df.index)\n    non_scale_df = df.drop(NUMERICAL_1+ORDINAL, axis=1)\n    df = pd.concat([scale_df, non_scale_df], axis=1)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:25.064360Z","iopub.execute_input":"2022-05-25T03:42:25.064826Z","iopub.status.idle":"2022-05-25T03:42:25.072346Z","shell.execute_reply.started":"2022-05-25T03:42:25.064788Z","shell.execute_reply":"2022-05-25T03:42:25.070719Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"train_X_scaled = standardization(tr_b_X, scalar, NUMERICAL_1, ORDINAL)\ntest_X_scaled = standardization(te_b, scalar, NUMERICAL_1, ORDINAL)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:25.074452Z","iopub.execute_input":"2022-05-25T03:42:25.074855Z","iopub.status.idle":"2022-05-25T03:42:25.106201Z","shell.execute_reply.started":"2022-05-25T03:42:25.074804Z","shell.execute_reply":"2022-05-25T03:42:25.105375Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"markdown","source":"## 2.6 Dimensionality Reduction\n- For now we have 233 features totally. The dimension is very high compared with sample size.\n- We can do some naive feature selection, e.g. remove the least correlated features to SalePrice and remove multicollinearity based on pairwise correlations.\n- Here we use PCA to get the most informative directions instead, which is a good way to reduce dimension, as well as remove multicollinearity and noise. It can also act as a regularizer.","metadata":{}},{"cell_type":"markdown","source":"### 2.6.1 Pairwise Correlations","metadata":{}},{"cell_type":"code","source":"p_corr_b = pd.concat([train_X_scaled, train_y], axis=1).corr(method='pearson')\ns_corr_b = pd.concat([train_X_scaled, train_y], axis=1).corr(method='spearman')","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:25.108184Z","iopub.execute_input":"2022-05-25T03:42:25.108553Z","iopub.status.idle":"2022-05-25T03:42:25.481379Z","shell.execute_reply.started":"2022-05-25T03:42:25.108507Z","shell.execute_reply":"2022-05-25T03:42:25.480222Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"high_corr_pairs(p_corr_b, s_corr_b)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:25.482910Z","iopub.execute_input":"2022-05-25T03:42:25.483308Z","iopub.status.idle":"2022-05-25T03:42:27.415977Z","shell.execute_reply.started":"2022-05-25T03:42:25.483132Z","shell.execute_reply":"2022-05-25T03:42:27.414955Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"markdown","source":"### 2.6.2 Features Most Correlated to SalePrice","metadata":{}},{"cell_type":"code","source":"print(\"Most correlated features (Pearson's) \")\nprint(p_corr_b['SalePrice'].abs().sort_values(ascending=False).iloc[1:11])\n\nprint(\"\\nMost correlated features (Spearman's) \")\nprint(s_corr_b['SalePrice'].abs().sort_values(ascending=False).iloc[1:11])\n\nprint(\"\\nLeast correlated features (Pearson's) \")\nprint(p_corr_b['SalePrice'].abs().sort_values(ascending=False).tail(10))\n\nprint(\"\\nLeast correlated features (Spearman's) \")\nprint(s_corr_b['SalePrice'].abs().sort_values(ascending=False).tail(10))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:27.417929Z","iopub.execute_input":"2022-05-25T03:42:27.418273Z","iopub.status.idle":"2022-05-25T03:42:27.436114Z","shell.execute_reply.started":"2022-05-25T03:42:27.418226Z","shell.execute_reply":"2022-05-25T03:42:27.434981Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"markdown","source":"### 2.6.3 PCA\n- The first 50 principal components can explain >90% of variance in the original data set.\n- The first 100 principal components can explain nearly 99% variance in the original data set.","metadata":{}},{"cell_type":"code","source":"pca = PCA(n_components=100)\npca.fit(train_X_scaled)\npve = pca.explained_variance_ratio_\n\nsns.scatterplot(x=range(0, len(pve)), y=pve.cumsum())\nplt.axhline(y=0.99, c='black', linestyle='--')\nplt.xlabel('Principal Component')\nplt.ylabel('Cumulative PVE')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:27.438385Z","iopub.execute_input":"2022-05-25T03:42:27.439078Z","iopub.status.idle":"2022-05-25T03:42:28.306108Z","shell.execute_reply.started":"2022-05-25T03:42:27.439028Z","shell.execute_reply":"2022-05-25T03:42:28.305088Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"def dimension_reduction(df_tr, pca):\n    df = df_tr.copy()\n    return pca.transform(df)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:28.307723Z","iopub.execute_input":"2022-05-25T03:42:28.308282Z","iopub.status.idle":"2022-05-25T03:42:28.313715Z","shell.execute_reply.started":"2022-05-25T03:42:28.308233Z","shell.execute_reply":"2022-05-25T03:42:28.312726Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"train_X = dimension_reduction(train_X_scaled, pca)\ntest_X = dimension_reduction(test_X_scaled, pca)\nprint(train_X.shape, test_X.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:28.315289Z","iopub.execute_input":"2022-05-25T03:42:28.315727Z","iopub.status.idle":"2022-05-25T03:42:28.361693Z","shell.execute_reply.started":"2022-05-25T03:42:28.315670Z","shell.execute_reply":"2022-05-25T03:42:28.360588Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"markdown","source":"# 3 Modelling","metadata":{}},{"cell_type":"markdown","source":"## 3.1 Simple Models\nIn this part, we build some basic models mostly using default hyperparameters without tuning and check the results. (Got some thoughts from [here](https://www.kaggle.com/code/massquantity/all-you-need-is-pca-lb-0-11421-top-4#Modeling-&-Evaluation))","metadata":{}},{"cell_type":"code","source":"models_dict = {'LR': LinearRegression(),\n               'RIDGE': Ridge(),\n               'Lasso': Lasso(alpha=0.01,max_iter=10000),\n               'ENet': ElasticNet(alpha=0.001,max_iter=10000),\n               'SVR': SVR(),\n               'LinSVR': LinearSVR(),\n               'KNN': KNeighborsRegressor(),\n               'Kernel': KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5),\n               'RF': RandomForestRegressor(),\n               'AdaBoost': AdaBoostRegressor(),\n               'ExTree': ExtraTreesRegressor(),\n               'Xgb': XGBRegressor()\n              }","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:51:10.911794Z","iopub.execute_input":"2022-05-25T03:51:10.912111Z","iopub.status.idle":"2022-05-25T03:51:10.919763Z","shell.execute_reply.started":"2022-05-25T03:51:10.912077Z","shell.execute_reply":"2022-05-25T03:51:10.918983Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"def rmse_cv(model, train_X, train_y):\n    rmse = np.sqrt(-cross_val_score(model, train_X, train_y, scoring=\"neg_mean_squared_error\", cv=5))\n    return rmse","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:51:15.180005Z","iopub.execute_input":"2022-05-25T03:51:15.180517Z","iopub.status.idle":"2022-05-25T03:51:15.185146Z","shell.execute_reply.started":"2022-05-25T03:51:15.180467Z","shell.execute_reply":"2022-05-25T03:51:15.184372Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"for name in models_dict.keys():\n    np.random.seed(42)\n    rmse = rmse_cv(models_dict[name], train_X, train_y)\n    print('{}: {:.6f}'.format(name, rmse.mean()))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:51:16.685723Z","iopub.execute_input":"2022-05-25T03:51:16.686212Z","iopub.status.idle":"2022-05-25T03:52:16.854297Z","shell.execute_reply.started":"2022-05-25T03:51:16.686163Z","shell.execute_reply":"2022-05-25T03:52:16.853558Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 Cross-validation and Hyperparameter Tuning\nHere we need to do hyperparameter tuning for each model and choose the model with the best performance. To avoid leakage, we can choose to apply nested cross-validation, which means we tune hyperparameters on an inner cross-validation and choose the best model on an outer cros-validation.","metadata":{}},{"cell_type":"code","source":"def hyper_tuning_cv(train_X, train_y, model, param_grid, if_nested=True):\n    inner_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n    outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n    \n    if if_nested:\n        #nested CV with hyperparameter tuning\n        reg = GridSearchCV(estimator=model, param_grid=param_grid, cv=inner_cv, scoring='neg_mean_squared_error')\n        score = np.sqrt(-cross_val_score(reg, train_X, train_y, scoring='neg_mean_squared_error', cv=outer_cv))\n    else:\n        # Non_nested parameter search and scoring\n        reg = GridSearchCV(estimator=model, param_grid=param_grid, cv=outer_cv, scoring='neg_mean_squared_error')\n        reg.fit(train_X, train_y)\n        score = np.sqrt(-reg.best_score_)\n    \n    return score.mean()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-25T05:05:09.000996Z","iopub.execute_input":"2022-05-25T05:05:09.001302Z","iopub.status.idle":"2022-05-25T05:05:09.010952Z","shell.execute_reply.started":"2022-05-25T05:05:09.001272Z","shell.execute_reply":"2022-05-25T05:05:09.009640Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"code","source":"hyper_tuning_cv(train_X, train_y, Lasso(), {'alpha': [0.01,0.05,0.001,0.005,0.0001,0.0005]}, True)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T05:05:09.493576Z","iopub.execute_input":"2022-05-25T05:05:09.493902Z","iopub.status.idle":"2022-05-25T05:05:10.846634Z","shell.execute_reply.started":"2022-05-25T05:05:09.493867Z","shell.execute_reply":"2022-05-25T05:05:10.845483Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"hyper_tuning_cv(train_X, train_y, Lasso(), {'alpha': [0.01,0.05,0.001,0.005,0.0001,0.0005]}, False)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T05:05:13.524668Z","iopub.execute_input":"2022-05-25T05:05:13.525006Z","iopub.status.idle":"2022-05-25T05:05:13.892827Z","shell.execute_reply.started":"2022-05-25T05:05:13.524973Z","shell.execute_reply":"2022-05-25T05:05:13.891547Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"hyper_tuning_cv(train_X, train_y, Ridge(), {'alpha': [50,30,10,1,0.1]}, True)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T05:06:04.057009Z","iopub.execute_input":"2022-05-25T05:06:04.057320Z","iopub.status.idle":"2022-05-25T05:06:04.752233Z","shell.execute_reply.started":"2022-05-25T05:06:04.057290Z","shell.execute_reply":"2022-05-25T05:06:04.751119Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"code","source":"hyper_tuning_cv(train_X, train_y, Ridge(), {'alpha': [50,30,10,1,0.1]}, False)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T05:06:11.530629Z","iopub.execute_input":"2022-05-25T05:06:11.530956Z","iopub.status.idle":"2022-05-25T05:06:11.771538Z","shell.execute_reply.started":"2022-05-25T05:06:11.530925Z","shell.execute_reply":"2022-05-25T05:06:11.770491Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"markdown","source":"# 4 Submission","metadata":{}},{"cell_type":"code","source":"# model = Ridge()\n# model.fit(train_X, train_y)\n# pred = np.exp(model.predict(test_X)) - 1\n\n# result = pd.DataFrame({'Id': df_te.index, 'SalePrice': pred})\n# result.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T03:42:28.445422Z","iopub.execute_input":"2022-05-25T03:42:28.446300Z","iopub.status.idle":"2022-05-25T03:42:28.463347Z","shell.execute_reply.started":"2022-05-25T03:42:28.446258Z","shell.execute_reply":"2022-05-25T03:42:28.462173Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}